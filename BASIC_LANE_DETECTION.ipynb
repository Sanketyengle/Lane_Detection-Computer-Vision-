{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "  return mpimg.imread(path)\n",
    "\n",
    "def show(image):\n",
    "  print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "  plt.imshow(image)\n",
    "\n",
    "def save(image, path = 'test.png'):\n",
    "  plt.imsave(path, image)\n",
    "\n",
    "def convert_to_color(image):\n",
    "  return np.dstack((image, image, image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray(raw_image):\n",
    "  '''convert the colored imaged to grayscale image'''\n",
    "  return cv2.cvtColor(raw_image, cv2.COLOR_RGB2GRAY)  \n",
    "\n",
    "def reduce_noise(gray_image, kernel_size):\n",
    "  '''reduce noise of grayscale image using gausian blur'''\n",
    "  return cv2.GaussianBlur(gray_image, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(blur_image, low_threshold, high_threshold):\n",
    "  '''find edges using canny transform algorithm'''\n",
    "  return cv2.Canny(blur_image, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertices(x, y, axc, bxc, cyc, dyc, maxyc = 1.0, maxxc = 1.0, startxc = 0.0):\n",
    "  ax = int(axc*x)\n",
    "  bx = int(bxc*x)\n",
    "  cy = int(cyc*y)\n",
    "  dy = int(dyc*y)\n",
    "  maxy = int(maxyc*y)\n",
    "  maxx = int(maxxc*x)\n",
    "  startx = int(startxc*x)\n",
    "  bottom_left = (startx, maxy)\n",
    "  top_left = (ax, cy)\n",
    "  top_right = (bx, dy)\n",
    "  bottom_right = (maxx, maxy)\n",
    "  vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "  return vertices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi(edge_image, vertices, ignore_value = 255):\n",
    "  '''get the polygon to be used to block out everything in the image except the region of interest'''\n",
    "  roi = np.zeros_like(edge_image)\n",
    "  cv2.fillPoly(roi, vertices, ignore_value)\n",
    "  return roi\n",
    "\n",
    "def mask(edge_image, roi):\n",
    "  '''block out everything in the image except the edges in the region of interest'''\n",
    "  return cv2.bitwise_and(edge_image, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(masked_edge_image, rho, theta_coef, min_votes, min_line_length, max_line_gap):\n",
    "  '''convert edges into lines using hough transform algorithm '''\n",
    "  theta = theta_coef*np.pi/180\n",
    "  return cv2.HoughLinesP(masked_edge_image, rho, theta, min_votes, np.array([]), minLineLength = min_line_length, maxLineGap = max_line_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(lines, image, color=[255, 0, 0], thickness = 2, thresh = 0.5):\n",
    "  ''' draw the lines on a blank image'''\n",
    "  lined_image = np.copy(image)*0\n",
    "  \n",
    "  if lines is not None:\n",
    "    for line in lines:\n",
    "      for x1,y1,x2,y2 in line:\n",
    "        slope, intercept = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "        if abs(slope) > thresh:\n",
    "          cv2.line(lined_image, (x1, y1), (x2, y2), color, thickness)\n",
    "        \n",
    "  return lined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equation of a line: y = slope*x + intercept \n",
    "# left lane has a positive slope, right lane has a negative slope \n",
    "\n",
    "def extrapolate_lines(lines, image, color=[255, 0, 0], thickness = 10, \n",
    "                      positive_thresh = 0.5, negative_thresh = 0.5):\n",
    "    \n",
    "  imshape = image.shape\n",
    "  image = np.copy(image)*0\n",
    "    \n",
    "  #initialize minimum and maximum y coordinate \n",
    "  minimum_y = image.shape[0] \n",
    "  maximum_y = image.shape[0]\n",
    "  \n",
    "  #initialize groups of values into empty lists\n",
    "  left_slopes = []\n",
    "  left_xs = []\n",
    "  left_ys = []   \n",
    "  right_slopes = []\n",
    "  right_xs = []\n",
    "  right_ys = []\n",
    "  \n",
    "  # segregate the small line segments into the left lane group or right lane group\n",
    "  if lines is not None:  \n",
    "    for line in lines:\n",
    "      for x1,y1,x2,y2 in line:\n",
    "        \n",
    "        # get the slope and intercept of the line (as defined by two points) using the polyfit function\n",
    "        slope, intercept = np.polyfit((x1,x2), (y1,y2), 1)\n",
    "            \n",
    "        if (slope > positive_thresh): #if positive slope, put value to left lane group\n",
    "          left_slopes += [slope]\n",
    "          left_xs += [x1, x2]\n",
    "          left_ys += [y1, y2]\n",
    "        elif (slope < negative_thresh): #if negative slope, put value to right lane group\n",
    "          right_slopes += [slope]\n",
    "          right_xs += [x1, x2]\n",
    "          right_ys += [y1, y2]\n",
    "        \n",
    "        # update the minimum y_coordinate based on values seen\n",
    "        minimum_y = min(min(y1, y2), minimum_y)\n",
    "  \n",
    "  #average all the values in each group to get the slope, x, and y\n",
    "  left_slope = np.mean(left_slopes)\n",
    "  left_x = np.mean(left_xs)\n",
    "  left_y = np.mean(left_ys)\n",
    "  right_slope = np.mean(right_slopes)\n",
    "  right_x = np.mean(right_xs)\n",
    "  right_y = np.mean(right_ys)\n",
    "    \n",
    "  #derive the intercept using the equation of the line and average value\n",
    "  left_intercept = left_y - (left_slope * left_x)\n",
    "  right_intercept = right_y - (right_slope * right_x)\n",
    "\n",
    "  if ((len(left_slopes) > 0) and (len(right_slopes) > 0)): #make sure we have points in each group\n",
    "    #derive the x coordinate using the equation of the lines and derived values\n",
    "    upper_left_x = int((minimum_y - left_intercept) / left_slope)\n",
    "    lower_left_x = int((maximum_y - left_intercept) / left_slope)\n",
    "    upper_right_x = int((minimum_y - right_intercept) / right_slope)\n",
    "    lower_right_x = int((maximum_y - right_intercept) / right_slope)\n",
    "    \n",
    "    #draw the line based on two points \n",
    "    cv2.line(image, (upper_left_x, minimum_y), (lower_left_x, maximum_y), color, thickness)\n",
    "    cv2.line(image, (upper_right_x, minimum_y), (lower_right_x, maximum_y), color, thickness)\n",
    "    \n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(first_image, second_image, α = 0.8, β = 0.5, λ = 0.0):\n",
    "    '''first_image * α + second_image * β + λ (colored)'''\n",
    "    return cv2.addWeighted(first_image, α, second_image, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "   #blur parameters\n",
    "  'kernel_size': 5, \n",
    "    \n",
    "   #canny transform parameters\n",
    "  'canny_lo': 100, \n",
    "  'canny_hi': 200, \n",
    "\n",
    "  #region of interest parameters\n",
    "  'ax_coef': 10.0/25,\n",
    "  'bx_coef': 14.0/25,\n",
    "  'cy_coef': 0.6,\n",
    "  'dy_coef': 0.6,\n",
    "  'maxy_coef': 1.0,\n",
    "  'maxx_coef': 1.0,\n",
    "  'startx_coef': 0.0,\n",
    "\n",
    "  #hough parameters\n",
    "  'rho': 1, \n",
    "  'theta_coef': 1, \n",
    "  'min_votes': 30, \n",
    "  'min_line_length': 20, \n",
    "  'max_line_gap': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(path, file, name, param = param):\n",
    "    \n",
    "  name = path + name\n",
    "\n",
    "  raw_image = read(path + file)\n",
    "  image = read(path + file)\n",
    "  save(image, path = name + '1-raw.png')\n",
    "  \n",
    "  gray_image = gray(image)\n",
    "  save(gray_image, path = name + '2-grey.png')\n",
    "    \n",
    "  blur_image = reduce_noise(gray_image, param['kernel_size'])\n",
    "  save(blur_image, path = name + '3-blur.png')\n",
    "    \n",
    "  edge_image = get_edges(blur_image, param['canny_lo'], param['canny_hi'])\n",
    "  save(edge_image, path = name + '4-edges.png')\n",
    "  \n",
    "  x = image.shape[1]\n",
    "  y = image.shape[0]\n",
    "  vertices = get_vertices(x, y, param['ax_coef'], param['bx_coef'],\n",
    "                                param['cy_coef'], param['dy_coef'],\n",
    "                                param['maxy_coef'], param['maxx_coef'], param['startx_coef'])\n",
    "  \n",
    "  roi = get_roi(edge_image, vertices)\n",
    "  save(roi, path = name + '5-roi.png')\n",
    "  \n",
    "  mask_image = mask(edge_image, roi)\n",
    "  save(mask_image, path = name + '6-mask.png')\n",
    "  \n",
    "  lines = get_lines(mask_image, param['rho'], param['theta_coef'],\n",
    "                           param['min_votes'], param['min_line_length'],\n",
    "                           param['max_line_gap'])\n",
    "   \n",
    "  line_image = draw(lines, raw_image)\n",
    "  save(line_image, path = name + '7-lines.png')\n",
    "  \n",
    "  \n",
    "  line_image2 = extrapolate_lines(lines, raw_image)\n",
    "  save(line_image2, path = name + '8-lines.png')\n",
    "\n",
    "  image = overlap(line_image, raw_image)\n",
    "  save(image, path = name + '9-overlap.png')\n",
    "\n",
    "  image = overlap(line_image2, raw_image)\n",
    "  save(image, path = name + '10-overlap.png')\n",
    "   \n",
    "\n",
    "pipeline(path = 'test_images/', file = 'solidWhiteCurve.jpg', name = 'A')\n",
    "pipeline(path = 'test_images/', file = 'solidWhiteRight.jpg', name = 'B')\n",
    "pipeline(path = 'test_images/', file = 'solidYellowCurve.jpg', name = 'C')\n",
    "pipeline(path = 'test_images/', file = 'solidYellowCurve2.jpg', name = 'D')\n",
    "pipeline(path = 'test_images/', file = 'solidYellowLeft.jpg', name = 'E')\n",
    "pipeline(path = 'test_images/', file = 'whiteCarLaneSwitch.jpg', name = 'F')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "\n",
    "  raw_image = np.copy(image)\n",
    "  gray_image = gray(image)    \n",
    "  blur_image = reduce_noise(gray_image, param['kernel_size'])\n",
    "    \n",
    "  edge_image = get_edges(blur_image, param['canny_lo'], param['canny_hi'])\n",
    "  \n",
    "  x, y = image.shape[1], image.shape[0]\n",
    "  vertices = get_vertices(x, y, param['ax_coef'], param['bx_coef'],\n",
    "                                param['cy_coef'], param['dy_coef'],\n",
    "                                param['maxx_coef'], param['maxy_coef'],\n",
    "                                param['startx_coef'])\n",
    "  roi = get_roi(edge_image, vertices)  \n",
    "  mask_image = mask(edge_image, roi)\n",
    "  \n",
    "  lines = get_lines(mask_image, param['rho'], param['theta_coef'],\n",
    "                           param['min_votes'], param['min_line_length'],\n",
    "                           param['max_line_gap'])\n",
    "   \n",
    "  #line_image = draw(lines, raw_image)  \n",
    "  #result = overlap(line_image, raw_image)\n",
    " \n",
    "  line_image2 = extrapolate_lines(lines, raw_image) \n",
    "  result = overlap(line_image2, raw_image)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video white.mp4.\n",
      "MoviePy - Writing audio in whiteTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video white.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attribute 'duration' not set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36muse_clip_fps_by_default\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m    133\u001b[0m              for (k,v) in k.items()}\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mconvert_masks_to_RGB\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_RGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mwrite_videofile\u001b[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    305\u001b[0m                            \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                            \u001b[0mffmpeg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mffmpeg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                            logger=logger)\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_temp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmake_audio\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36mffmpeg_write_video\u001b[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[0m\n\u001b[1;32m    214\u001b[0m                                 \u001b[0mpreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbitrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbitrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                                 \u001b[0maudiofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                                 ffmpeg_params=ffmpeg_params) as writer:\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mnframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/video/io/ffmpeg_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, size, fps, codec, audiofile, preset, bitrate, withmask, logfile, threads, ffmpeg_params)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;34m'-s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%dx%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;34m'-pix_fmt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rgba'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwithmask\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'rgb24'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;34m'-r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%.02f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;34m'-an'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         ]\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"/home/guruji/Downloads/advanced-lane-detection-master/A-BASIC-LANE-DETECTION/videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "MoviePy error: the file solidYellowLeft.mp4 could not be found!\nPlease check that you entered the correct path.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0cafafa5cf2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myellow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'yellow.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclip2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'solidYellowLeft.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0myellow_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yellow_clip.write_videofile(yellow_output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, has_mask, audio, audio_buffersize, target_resolution, resize_algorithm, audio_fps, audio_nbytes, verbose, fps_source)\u001b[0m\n\u001b[1;32m     89\u001b[0m                                          \u001b[0mtarget_resolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_resolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                                          \u001b[0mresize_algo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresize_algorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                          fps_source=fps_source)\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Make some of the reader's attributes accessible from the clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, print_infos, bufsize, pix_fmt, check_duration, target_resolution, resize_algo, fps_source)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         infos = ffmpeg_parse_infos(filename, print_infos, check_duration,\n\u001b[0;32m---> 36\u001b[0;31m                                    fps_source)\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_fps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/data_science/lib/python3.6/site-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mffmpeg_parse_infos\u001b[0;34m(filename, print_infos, check_duration, fps_source)\u001b[0m\n\u001b[1;32m    270\u001b[0m         raise IOError((\"MoviePy error: the file %s could not be found!\\n\"\n\u001b[1;32m    271\u001b[0m                       \u001b[0;34m\"Please check that you entered the correct \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                       \"path.\")%filename)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: MoviePy error: the file solidYellowLeft.mp4 could not be found!\nPlease check that you entered the correct path."
     ]
    }
   ],
   "source": [
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "   #blur parameters\n",
    "  'kernel_size': 3, \n",
    "    \n",
    "   #canny transform parameters\n",
    "  'canny_lo': 50, \n",
    "  'canny_hi': 150, \n",
    "\n",
    "  #region of interest parameters\n",
    "  'ax_coef': 0.41,\n",
    "  'bx_coef': 0.60,\n",
    "  'cy_coef': 0.65,\n",
    "  'dy_coef': 0.65,\n",
    "  'maxy_coef': 0.9,\n",
    "  'maxx_coef': 0.85,\n",
    "  'startx_coef': 0.15,\n",
    "\n",
    "  #hough parameters\n",
    "  'rho': 1, \n",
    "  'theta_coef': 1, \n",
    "  'min_votes': 20, \n",
    "  'min_line_length': 50, \n",
    "  'max_line_gap': 20\n",
    "}\n",
    "\n",
    "def process(image):\n",
    "\n",
    "  raw_image = np.copy(image)\n",
    "\n",
    "  gray_image = gray(image)    \n",
    "  blur_image = reduce_noise(gray_image, p['kernel_size'])\n",
    "    \n",
    "  edge_image = get_edges(blur_image, p['canny_lo'], p['canny_hi'])\n",
    "  \n",
    "  #return convert_to_color(edge_image) #check if canny parameters detect edges of lanes\n",
    "\n",
    "  x = image.shape[1]\n",
    "  y = image.shape[0]\n",
    "  vertices = get_vertices(x, y, p['ax_coef'], p['bx_coef'],\n",
    "                                p['cy_coef'], p['dy_coef'],\n",
    "                                p['maxy_coef'], p['maxx_coef'], p['startx_coef'])\n",
    "  \n",
    "  roi = get_roi(edge_image, vertices)\n",
    "  mask_image = mask(edge_image, roi)\n",
    "  \n",
    "  #return overlap(convert_to_color(roi), raw_image) #check if roi is good\n",
    "    \n",
    "  lines = get_lines(mask_image, p['rho'], p['theta_coef'],\n",
    "                                p['min_votes'], p['min_line_length'],\n",
    "                                p['max_line_gap'], )\n",
    "   \n",
    "  #line_image = draw(lines, raw_image, thresh = 0.5)  \n",
    "  #result = overlap(line_image, raw_image)\n",
    " \n",
    "  line_image2 = extrapolate_lines(lines, raw_image, \n",
    "                                  positive_thresh = 0.5, negative_thresh = -0.5) \n",
    "  result = overlap(line_image2, raw_image)\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:16<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 6.35 s, sys: 1.68 s, total: 8.03 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "challenge_output = 'extra.mp4'\n",
    "clip2 = VideoFileClip('challenge.mp4')\n",
    "challenge_clip = clip2.fl_image(process)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
